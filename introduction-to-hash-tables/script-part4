


== Part 4 ===

In this part of the lecture we're going quickly go over a little bit
of theory. We won't be deriving an proving any theorems so if you are
interested in that discussion be sure to checkout out the references
section.

The hash table implementation that we covered was simple and easy
to implement. It has an advantage that it doesn't really require pointers
to implement.

Open addressing hash tables have the potential for better performance 
during key look ups than a pointer based hash table because there is no
overhead related to storing and following pointers,

Additionally this open addressing implementation could be more memory 
efficent compared to a chaining implementation if the hash records take up 
less memory than the pointers pointser that would be used a chaining 
implementation and the percentage of full buckets isn't too low. 
Otherwise we'd have a hash table that uses allocated memory but is 
mostly empty.

One disadvantage of an open addressing hash tables aren't well suited 
to deletion operations.

If you need to support the ability to remove a key and its record then
a chaining solution is preferred.


We can describe how full a hash table is by calculating its load factor.


The load factor is defined as

    alpha = n/m

where n is the number occupied buckets and m is the total number of buckets.

In an open addressing hash table n<=m and alpha is <= 1.

We can use alpha to describe how many buckets, on average, 
will be probed when searching for a key


The following equestions assume that our hash function 
does a good job of distributing keys uniformly in the hash table.

In an unsuccessful member operation,  that is when the 
target key isn't found in the hash table, we can expect the average 
number of buckets searched to be no more than 

  1 / (1 - alpha) 

Suppose that the hash table is half-full, then alpha is == .50.

And we can expect to search no more than 

  1 / (1 - 0.5) == 2

buckets.

    [Action: Show a probe sequence example]

Notice that an unsuccessful member and insertion operation 
go through the same probing sequence except that the insertion 
operation inserts a new record at the end of its sequence.

Thus the both the insertion and member operations 
can be described with the same expression. 

The average number of probes for an insertion operation is

  1 / (1 - theta) assuming uniform hashing

buckets.

We can also describe a successful member operation.

Say the target key is in the hash table, then the number
of buckets that will be probed on average is 

  (1 / theta) * ln(1 / 1 - theta) assuming uniform hashing 


For example if the hash table is half full then a successful member
operation probes at most 1.387 buckets.

Notice what happens as the load factor alpha aproaches 1.

As the load factor approaches 1 the number of bucket probes
increases dramatically.

Another advantage that chaining hash tables have over open addressing hash
tables is that they degrade linearly as the load factor approaches 1 and 
surpasses 1. 

Depending on your performance needs,
once a load factor gets too large it may be a good idea to
add more buckets to the hash table.

A simple way of doing this is to allocate a hash table and reinsert the
hash records into the new array.

Although this may sound like an expensive operation, eventually it will 
will be more efficient than continuing to use an overloaded hash table.

That's it for this introduction to hash tables lesson, be sure to try and
practice what you've learned by completing the practice exercises. Good luck!
